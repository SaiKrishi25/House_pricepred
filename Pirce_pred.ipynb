{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785ba3c2",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d73d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split #sklearn for train and test split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e9241",
   "metadata": {},
   "source": [
    "# Defining compare_predictions for future call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07eceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions(preds_untrained, preds_trained, true_values):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(true_values, preds_untrained)\n",
    "    plt.title('Predictions Before Training')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(true_values, preds_trained)\n",
    "    plt.title('Predictions After Training')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e162e18",
   "metadata": {},
   "source": [
    "# Reading the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a38f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_price.csv') #defining the dataframe to load and read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e986db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2008.912800</td>\n",
       "      <td>18.945000</td>\n",
       "      <td>4.977800</td>\n",
       "      <td>4.915000</td>\n",
       "      <td>84.97140</td>\n",
       "      <td>124.994200</td>\n",
       "      <td>13906.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.457578</td>\n",
       "      <td>11.329539</td>\n",
       "      <td>3.199837</td>\n",
       "      <td>3.142889</td>\n",
       "      <td>3.16199</td>\n",
       "      <td>3.167992</td>\n",
       "      <td>1020.774876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>11263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>13197.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>13893.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>14614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>16964.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date          age     distance       stores    latitude  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.00000   \n",
       "mean   2008.912800    18.945000     4.977800     4.915000    84.97140   \n",
       "std       5.457578    11.329539     3.199837     3.142889     3.16199   \n",
       "min    2000.000000     0.000000     0.000000     0.000000    80.00000   \n",
       "25%    2004.000000     9.000000     2.000000     2.000000    82.00000   \n",
       "50%    2009.000000    19.000000     5.000000     5.000000    85.00000   \n",
       "75%    2014.000000    29.000000     8.000000     8.000000    88.00000   \n",
       "max    2018.000000    38.000000    10.000000    10.000000    90.00000   \n",
       "\n",
       "         longitude         price  \n",
       "count  5000.000000   5000.000000  \n",
       "mean    124.994200  13906.638600  \n",
       "std       3.167992   1020.774876  \n",
       "min     120.000000  11263.000000  \n",
       "25%     122.000000  13197.750000  \n",
       "50%     125.000000  13893.500000  \n",
       "75%     128.000000  14614.000000  \n",
       "max     130.000000  16964.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b2bd5",
   "metadata": {},
   "source": [
    "# Data preprocessing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa33239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>121</td>\n",
       "      <td>14264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>121</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>12029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>14157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  distance  stores  latitude  longitude  price\n",
       "0   21         9       6        84        121  14264\n",
       "1    4         2       3        86        121  12032\n",
       "2   18         3       7        90        120  13560\n",
       "3   13         2       2        80        128  12029\n",
       "4   25         5       8        81        122  14157"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe2784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance  stores  latitude  longitude  price\n",
       "0        False   False     False      False  False\n",
       "1        False   False     False      False  False\n",
       "2        False   False     False      False  False\n",
       "3        False   False     False      False  False\n",
       "4        False   False     False      False  False\n",
       "...        ...     ...       ...        ...    ...\n",
       "4995     False   False     False      False  False\n",
       "4996     False   False     False      False  False\n",
       "4997     False   False     False      False  False\n",
       "4998     False   False     False      False  False\n",
       "4999     False   False     False      False  False\n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna() #viewing the rows with false values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501f3962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>121</td>\n",
       "      <td>14264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>121</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>12029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>14157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>13539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>129</td>\n",
       "      <td>14757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>14102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>128</td>\n",
       "      <td>14313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>12770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  distance  stores  latitude  longitude  price\n",
       "0      21         9       6        84        121  14264\n",
       "1       4         2       3        86        121  12032\n",
       "2      18         3       7        90        120  13560\n",
       "3      13         2       2        80        128  12029\n",
       "4      25         5       8        81        122  14157\n",
       "...   ...       ...     ...       ...        ...    ...\n",
       "4995   17         6       3        90        125  13539\n",
       "4996    7        10       0        85        129  14757\n",
       "4997    6        10       5        90        125  14102\n",
       "4998   37         3       5        81        128  14313\n",
       "4999    9         1       9        90        127  12770\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna() #drop the false or NaN values from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9458abbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance     0\n",
       "stores       0\n",
       "latitude     0\n",
       "longitude    0\n",
       "price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b9b3b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(\"price\")\n",
    "plt.show() #ploting the price history from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3809d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, 1:] #defining the dataframe(pandas) for the rows and columns. \n",
    "df_norm = (df - df.mean()) / df.std() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78184389",
   "metadata": {},
   "source": [
    "# Declare X and Y variables for test and train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a2ace8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm.iloc[:, :5]\n",
    "Y = df_norm.iloc[:, -1]\n",
    "X_arr = X.values\n",
    "Y_arr = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03767b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25700164e+00,  3.45223786e-01, -3.07211584e-01,\n",
       "        -1.26079862e+00,  3.50088358e-01],\n",
       "       [-9.30609988e-01, -6.09312028e-01,  3.25301457e-01,\n",
       "        -1.26079862e+00, -1.83648583e+00],\n",
       "       [-6.18094041e-01,  6.63402390e-01,  1.59032754e+00,\n",
       "        -1.57645598e+00, -3.39583789e-01],\n",
       "       ...,\n",
       "       [ 1.56951759e+00,  2.70451814e-02,  1.59032754e+00,\n",
       "         1.83081268e-03,  1.91385392e-01],\n",
       "       [-6.18094041e-01,  2.70451814e-02, -1.25598114e+00,\n",
       "         9.48802888e-01,  3.98091106e-01],\n",
       "       [-1.24312594e+00,  1.29975960e+00,  1.59032754e+00,\n",
       "         6.33145529e-01, -1.11350566e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr #viewing X array values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a94a720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35008836, -1.83648583, -0.33958379, ...,  0.19138539,\n",
       "        0.39809111, -1.11350566])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_arr #viewing Y array values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8139edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, Y_arr, test_size=0.01, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2598dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(): #define the model before training. \n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(5,), activation='relu'),Dense(20, activation='relu'),\n",
    "        Dense(5, activation='relu'),Dense(1)])\n",
    "    model.compile(loss='mse', optimizer='adadelta')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "881af121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "preds_on_untrained = model.predict(X_test) #prediction before training with respect to X. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc128b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c938a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 1.0540 - val_loss: 0.7987\n",
      "Epoch 2/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 1.0516 - val_loss: 0.7966\n",
      "Epoch 3/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0491 - val_loss: 0.7946\n",
      "Epoch 4/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0467 - val_loss: 0.7925\n",
      "Epoch 5/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0443 - val_loss: 0.7905\n",
      "Epoch 6/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0418 - val_loss: 0.7884\n",
      "Epoch 7/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 1.0394 - val_loss: 0.7864\n",
      "Epoch 8/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0369 - val_loss: 0.7843\n",
      "Epoch 9/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0344 - val_loss: 0.7822\n",
      "Epoch 10/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0319 - val_loss: 0.7801\n",
      "Epoch 11/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0295 - val_loss: 0.7780\n",
      "Epoch 12/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0270 - val_loss: 0.7760\n",
      "Epoch 13/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0246 - val_loss: 0.7740\n",
      "Epoch 14/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0222 - val_loss: 0.7719\n",
      "Epoch 15/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0198 - val_loss: 0.7699\n",
      "Epoch 16/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0174 - val_loss: 0.7679\n",
      "Epoch 17/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0150 - val_loss: 0.7659\n",
      "Epoch 18/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0126 - val_loss: 0.7639\n",
      "Epoch 19/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0103 - val_loss: 0.7620\n",
      "Epoch 20/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0079 - val_loss: 0.7601\n",
      "Epoch 21/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0056 - val_loss: 0.7581\n",
      "Epoch 22/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0032 - val_loss: 0.7562\n",
      "Epoch 23/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.0009 - val_loss: 0.7542\n",
      "Epoch 24/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9986 - val_loss: 0.7523\n",
      "Epoch 25/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9963 - val_loss: 0.7504\n",
      "Epoch 26/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9940 - val_loss: 0.7485\n",
      "Epoch 27/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9917 - val_loss: 0.7466\n",
      "Epoch 28/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9895 - val_loss: 0.7447\n",
      "Epoch 29/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9872 - val_loss: 0.7428\n",
      "Epoch 30/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9851 - val_loss: 0.7411\n",
      "Epoch 31/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9829 - val_loss: 0.7393\n",
      "Epoch 32/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9808 - val_loss: 0.7375\n",
      "Epoch 33/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9786 - val_loss: 0.7357\n",
      "Epoch 34/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9764 - val_loss: 0.7339\n",
      "Epoch 35/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9742 - val_loss: 0.7321\n",
      "Epoch 36/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9720 - val_loss: 0.7302\n",
      "Epoch 37/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9698 - val_loss: 0.7284\n",
      "Epoch 38/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9676 - val_loss: 0.7266\n",
      "Epoch 39/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9654 - val_loss: 0.7248\n",
      "Epoch 40/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9633 - val_loss: 0.7230\n",
      "Epoch 41/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.7213\n",
      "Epoch 42/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.7195\n",
      "Epoch 43/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.9569 - val_loss: 0.7177\n",
      "Epoch 44/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9547 - val_loss: 0.7159\n",
      "Epoch 45/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9526 - val_loss: 0.7141\n",
      "Epoch 46/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 0.7123\n",
      "Epoch 47/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.9484 - val_loss: 0.7105\n",
      "Epoch 48/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.9464 - val_loss: 0.7088\n",
      "Epoch 49/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 0.7070\n",
      "Epoch 50/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.9423 - val_loss: 0.7053\n",
      "Epoch 51/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.9402 - val_loss: 0.7035\n",
      "Epoch 52/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.9382 - val_loss: 0.7018\n",
      "Epoch 53/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9361 - val_loss: 0.7000\n",
      "Epoch 54/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.6983\n",
      "Epoch 55/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.9320 - val_loss: 0.6966\n",
      "Epoch 56/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.9300 - val_loss: 0.6949\n",
      "Epoch 57/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9280 - val_loss: 0.6932\n",
      "Epoch 58/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.6915\n",
      "Epoch 59/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.6899\n",
      "Epoch 60/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9221 - val_loss: 0.6883\n",
      "Epoch 61/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 0.6866\n",
      "Epoch 62/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 0.6850\n",
      "Epoch 63/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9163 - val_loss: 0.6834\n",
      "Epoch 64/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9143 - val_loss: 0.6818\n",
      "Epoch 65/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9124 - val_loss: 0.6803\n",
      "Epoch 66/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9105 - val_loss: 0.6787\n",
      "Epoch 67/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9085 - val_loss: 0.6771\n",
      "Epoch 68/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9066 - val_loss: 0.6756\n",
      "Epoch 69/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9047 - val_loss: 0.6740\n",
      "Epoch 70/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9028 - val_loss: 0.6725\n",
      "Epoch 71/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.9009 - val_loss: 0.6710\n",
      "Epoch 72/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8990 - val_loss: 0.6695\n",
      "Epoch 73/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8971 - val_loss: 0.6680\n",
      "Epoch 74/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8952 - val_loss: 0.6665\n",
      "Epoch 75/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8933 - val_loss: 0.6650\n",
      "Epoch 76/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8914 - val_loss: 0.6635\n",
      "Epoch 77/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8895 - val_loss: 0.6620\n",
      "Epoch 78/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8876 - val_loss: 0.6605\n",
      "Epoch 79/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8857 - val_loss: 0.6590\n",
      "Epoch 80/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8838 - val_loss: 0.6575\n",
      "Epoch 81/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8820 - val_loss: 0.6561\n",
      "Epoch 82/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8801 - val_loss: 0.6546\n",
      "Epoch 83/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8782 - val_loss: 0.6531\n",
      "Epoch 84/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8763 - val_loss: 0.6516\n",
      "Epoch 85/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8744 - val_loss: 0.6502\n",
      "Epoch 86/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8726 - val_loss: 0.6487\n",
      "Epoch 87/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8707 - val_loss: 0.6473\n",
      "Epoch 88/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8689 - val_loss: 0.6459\n",
      "Epoch 89/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8671 - val_loss: 0.6445\n",
      "Epoch 90/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8653 - val_loss: 0.6431\n",
      "Epoch 91/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8634 - val_loss: 0.6416\n",
      "Epoch 92/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8616 - val_loss: 0.6402\n",
      "Epoch 93/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8598 - val_loss: 0.6388\n",
      "Epoch 94/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8580 - val_loss: 0.6374\n",
      "Epoch 95/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8562 - val_loss: 0.6360\n",
      "Epoch 96/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8545 - val_loss: 0.6347\n",
      "Epoch 97/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8527 - val_loss: 0.6333\n",
      "Epoch 98/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8509 - val_loss: 0.6319\n",
      "Epoch 99/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8491 - val_loss: 0.6305\n",
      "Epoch 100/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8474 - val_loss: 0.6291\n",
      "Epoch 101/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8456 - val_loss: 0.6277\n",
      "Epoch 102/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8438 - val_loss: 0.6264\n",
      "Epoch 103/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8420 - val_loss: 0.6250\n",
      "Epoch 104/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8403 - val_loss: 0.6236\n",
      "Epoch 105/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8386 - val_loss: 0.6223\n",
      "Epoch 106/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8368 - val_loss: 0.6209\n",
      "Epoch 107/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8351 - val_loss: 0.6196\n",
      "Epoch 108/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8334 - val_loss: 0.6183\n",
      "Epoch 109/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8317 - val_loss: 0.6170\n",
      "Epoch 110/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8300 - val_loss: 0.6156\n",
      "Epoch 111/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8283 - val_loss: 0.6143\n",
      "Epoch 112/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8266 - val_loss: 0.6130\n",
      "Epoch 113/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8248 - val_loss: 0.6117\n",
      "Epoch 114/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8232 - val_loss: 0.6105\n",
      "Epoch 115/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8214 - val_loss: 0.6092\n",
      "Epoch 116/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8197 - val_loss: 0.6079\n",
      "Epoch 117/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8180 - val_loss: 0.6066\n",
      "Epoch 118/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8163 - val_loss: 0.6054\n",
      "Epoch 119/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8145 - val_loss: 0.6042\n",
      "Epoch 120/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8129 - val_loss: 0.6031\n",
      "Epoch 121/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8112 - val_loss: 0.6020\n",
      "Epoch 122/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8095 - val_loss: 0.6008\n",
      "Epoch 123/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8078 - val_loss: 0.5997\n",
      "Epoch 124/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8062 - val_loss: 0.5985\n",
      "Epoch 125/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8045 - val_loss: 0.5974\n",
      "Epoch 126/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8029 - val_loss: 0.5963\n",
      "Epoch 127/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8013 - val_loss: 0.5951\n",
      "Epoch 128/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7996 - val_loss: 0.5940\n",
      "Epoch 129/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7979 - val_loss: 0.5928\n",
      "Epoch 130/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7963 - val_loss: 0.5917\n",
      "Epoch 131/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7946 - val_loss: 0.5905\n",
      "Epoch 132/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7930 - val_loss: 0.5894\n",
      "Epoch 133/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7914 - val_loss: 0.5883\n",
      "Epoch 134/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7897 - val_loss: 0.5871\n",
      "Epoch 135/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7881 - val_loss: 0.5859\n",
      "Epoch 136/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7865 - val_loss: 0.5847\n",
      "Epoch 137/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7850 - val_loss: 0.5835\n",
      "Epoch 138/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7834 - val_loss: 0.5824\n",
      "Epoch 139/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7818 - val_loss: 0.5812\n",
      "Epoch 140/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7802 - val_loss: 0.5800\n",
      "Epoch 141/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7787 - val_loss: 0.5788\n",
      "Epoch 142/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7771 - val_loss: 0.5775\n",
      "Epoch 143/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7755 - val_loss: 0.5763\n",
      "Epoch 144/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7739 - val_loss: 0.5751\n",
      "Epoch 145/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7724 - val_loss: 0.5739\n",
      "Epoch 146/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 0.5727\n",
      "Epoch 147/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 0.5715\n",
      "Epoch 148/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7676 - val_loss: 0.5703\n",
      "Epoch 149/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7661 - val_loss: 0.5691\n",
      "Epoch 150/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7645 - val_loss: 0.5679\n",
      "Epoch 151/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7629 - val_loss: 0.5667\n",
      "Epoch 152/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7613 - val_loss: 0.5654\n",
      "Epoch 153/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 0.5641\n",
      "Epoch 154/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7582 - val_loss: 0.5628\n",
      "Epoch 155/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7566 - val_loss: 0.5616\n",
      "Epoch 156/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 0.5603\n",
      "Epoch 157/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 0.5590\n",
      "Epoch 158/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7520 - val_loss: 0.5578\n",
      "Epoch 159/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7504 - val_loss: 0.5565\n",
      "Epoch 160/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7489 - val_loss: 0.5552\n",
      "Epoch 161/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7473 - val_loss: 0.5540\n",
      "Epoch 162/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7458 - val_loss: 0.5527\n",
      "Epoch 163/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7442 - val_loss: 0.5514\n",
      "Epoch 164/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7427 - val_loss: 0.5501\n",
      "Epoch 165/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7411 - val_loss: 0.5489\n",
      "Epoch 166/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7395 - val_loss: 0.5476\n",
      "Epoch 167/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7379 - val_loss: 0.5463\n",
      "Epoch 168/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7364 - val_loss: 0.5451\n",
      "Epoch 169/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7349 - val_loss: 0.5438\n",
      "Epoch 170/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7333 - val_loss: 0.5426\n",
      "Epoch 171/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.5413\n",
      "Epoch 172/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7302 - val_loss: 0.5400\n",
      "Epoch 173/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 0.5388\n",
      "Epoch 174/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 0.5375\n",
      "Epoch 175/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7254 - val_loss: 0.5362\n",
      "Epoch 176/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7238 - val_loss: 0.5349\n",
      "Epoch 177/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7222 - val_loss: 0.5337\n",
      "Epoch 178/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.5324\n",
      "Epoch 179/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7190 - val_loss: 0.5312\n",
      "Epoch 180/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7174 - val_loss: 0.5299\n",
      "Epoch 181/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7158 - val_loss: 0.5287\n",
      "Epoch 182/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7141 - val_loss: 0.5275\n",
      "Epoch 183/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7125 - val_loss: 0.5262\n",
      "Epoch 184/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7108 - val_loss: 0.5250\n",
      "Epoch 185/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7092 - val_loss: 0.5237\n",
      "Epoch 186/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7076 - val_loss: 0.5225\n",
      "Epoch 187/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7060 - val_loss: 0.5213\n",
      "Epoch 188/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7043 - val_loss: 0.5201\n",
      "Epoch 189/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7027 - val_loss: 0.5188\n",
      "Epoch 190/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7010 - val_loss: 0.5176\n",
      "Epoch 191/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6993 - val_loss: 0.5163\n",
      "Epoch 192/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6977 - val_loss: 0.5151\n",
      "Epoch 193/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6960 - val_loss: 0.5138\n",
      "Epoch 194/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6943 - val_loss: 0.5125\n",
      "Epoch 195/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6926 - val_loss: 0.5113\n",
      "Epoch 196/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6909 - val_loss: 0.5101\n",
      "Epoch 197/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6892 - val_loss: 0.5088\n",
      "Epoch 198/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6875 - val_loss: 0.5076\n",
      "Epoch 199/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6858 - val_loss: 0.5063\n",
      "Epoch 200/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6841 - val_loss: 0.5051\n",
      "Epoch 201/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6823 - val_loss: 0.5039\n",
      "Epoch 202/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6806 - val_loss: 0.5026\n",
      "Epoch 203/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6789 - val_loss: 0.5014\n",
      "Epoch 204/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6771 - val_loss: 0.5001\n",
      "Epoch 205/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6753 - val_loss: 0.4989\n",
      "Epoch 206/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6736 - val_loss: 0.4976\n",
      "Epoch 207/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6718 - val_loss: 0.4964\n",
      "Epoch 208/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6700 - val_loss: 0.4952\n",
      "Epoch 209/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6682 - val_loss: 0.4939\n",
      "Epoch 210/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6664 - val_loss: 0.4927\n",
      "Epoch 211/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6646 - val_loss: 0.4915\n",
      "Epoch 212/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6628 - val_loss: 0.4902\n",
      "Epoch 213/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6610 - val_loss: 0.4890\n",
      "Epoch 214/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6591 - val_loss: 0.4877\n",
      "Epoch 215/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6572 - val_loss: 0.4865\n",
      "Epoch 216/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6554 - val_loss: 0.4852\n",
      "Epoch 217/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6535 - val_loss: 0.4840\n",
      "Epoch 218/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6516 - val_loss: 0.4828\n",
      "Epoch 219/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6497 - val_loss: 0.4815\n",
      "Epoch 220/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6478 - val_loss: 0.4802\n",
      "Epoch 221/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6458 - val_loss: 0.4789\n",
      "Epoch 222/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6438 - val_loss: 0.4776\n",
      "Epoch 223/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6418 - val_loss: 0.4763\n",
      "Epoch 224/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6398 - val_loss: 0.4750\n",
      "Epoch 225/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6379 - val_loss: 0.4738\n",
      "Epoch 226/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6359 - val_loss: 0.4725\n",
      "Epoch 227/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6339 - val_loss: 0.4712\n",
      "Epoch 228/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6319 - val_loss: 0.4700\n",
      "Epoch 229/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6299 - val_loss: 0.4687\n",
      "Epoch 230/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6279 - val_loss: 0.4673\n",
      "Epoch 231/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6259 - val_loss: 0.4660\n",
      "Epoch 232/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 0.4646\n",
      "Epoch 233/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 0.4632\n",
      "Epoch 234/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 0.4619\n",
      "Epoch 235/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.4605\n",
      "Epoch 236/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.4590\n",
      "Epoch 237/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.4575\n",
      "Epoch 238/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.4561\n",
      "Epoch 239/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6092 - val_loss: 0.4546\n",
      "Epoch 240/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.4532\n",
      "Epoch 241/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6052 - val_loss: 0.4517\n",
      "Epoch 242/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.4502\n",
      "Epoch 243/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.4487\n",
      "Epoch 244/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 0.4471\n",
      "Epoch 245/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 0.4456\n",
      "Epoch 246/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 0.4441\n",
      "Epoch 247/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 0.4426\n",
      "Epoch 248/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 0.4411\n",
      "Epoch 249/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 0.4395\n",
      "Epoch 250/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 0.4380\n",
      "Epoch 251/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5841 - val_loss: 0.4364\n",
      "Epoch 252/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.4349\n",
      "Epoch 253/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 0.4334\n",
      "Epoch 254/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5778 - val_loss: 0.4319\n",
      "Epoch 255/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5757 - val_loss: 0.4304\n",
      "Epoch 256/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5736 - val_loss: 0.4288\n",
      "Epoch 257/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5714 - val_loss: 0.4273\n",
      "Epoch 258/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5693 - val_loss: 0.4258\n",
      "Epoch 259/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5671 - val_loss: 0.4243\n",
      "Epoch 260/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5649 - val_loss: 0.4228\n",
      "Epoch 261/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5627 - val_loss: 0.4213\n",
      "Epoch 262/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5606 - val_loss: 0.4198\n",
      "Epoch 263/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5584 - val_loss: 0.4183\n",
      "Epoch 264/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5561 - val_loss: 0.4168\n",
      "Epoch 265/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5539 - val_loss: 0.4153\n",
      "Epoch 266/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5517 - val_loss: 0.4138\n",
      "Epoch 267/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5495 - val_loss: 0.4124\n",
      "Epoch 268/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5473 - val_loss: 0.4109\n",
      "Epoch 269/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5451 - val_loss: 0.4094\n",
      "Epoch 270/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5429 - val_loss: 0.4079\n",
      "Epoch 271/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 0.4064\n",
      "Epoch 272/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5384 - val_loss: 0.4049\n",
      "Epoch 273/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5362 - val_loss: 0.4034\n",
      "Epoch 274/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5339 - val_loss: 0.4018\n",
      "Epoch 275/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5317 - val_loss: 0.4002\n",
      "Epoch 276/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5294 - val_loss: 0.3985\n",
      "Epoch 277/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 0.3969\n",
      "Epoch 278/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 0.3953\n",
      "Epoch 279/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5226 - val_loss: 0.3938\n",
      "Epoch 280/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5204 - val_loss: 0.3921\n",
      "Epoch 281/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5181 - val_loss: 0.3905\n",
      "Epoch 282/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5157 - val_loss: 0.3889\n",
      "Epoch 283/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5134 - val_loss: 0.3873\n",
      "Epoch 284/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5111 - val_loss: 0.3856\n",
      "Epoch 285/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5088 - val_loss: 0.3840\n",
      "Epoch 286/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5064 - val_loss: 0.3824\n",
      "Epoch 287/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5041 - val_loss: 0.3807\n",
      "Epoch 288/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5018 - val_loss: 0.3789\n",
      "Epoch 289/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4995 - val_loss: 0.3772\n",
      "Epoch 290/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4971 - val_loss: 0.3754\n",
      "Epoch 291/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4948 - val_loss: 0.3737\n",
      "Epoch 292/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4925 - val_loss: 0.3720\n",
      "Epoch 293/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4902 - val_loss: 0.3702\n",
      "Epoch 294/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4878 - val_loss: 0.3685\n",
      "Epoch 295/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4855 - val_loss: 0.3668\n",
      "Epoch 296/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4832 - val_loss: 0.3651\n",
      "Epoch 297/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4809 - val_loss: 0.3635\n",
      "Epoch 298/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4786 - val_loss: 0.3618\n",
      "Epoch 299/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4763 - val_loss: 0.3601\n",
      "Epoch 300/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4740 - val_loss: 0.3584\n",
      "Epoch 301/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4717 - val_loss: 0.3567\n",
      "Epoch 302/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4694 - val_loss: 0.3550\n",
      "Epoch 303/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4671 - val_loss: 0.3533\n",
      "Epoch 304/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4648 - val_loss: 0.3516\n",
      "Epoch 305/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4625 - val_loss: 0.3499\n",
      "Epoch 306/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4601 - val_loss: 0.3482\n",
      "Epoch 307/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4579 - val_loss: 0.3465\n",
      "Epoch 308/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4556 - val_loss: 0.3449\n",
      "Epoch 309/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4533 - val_loss: 0.3433\n",
      "Epoch 310/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4510 - val_loss: 0.3417\n",
      "Epoch 311/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4488 - val_loss: 0.3401\n",
      "Epoch 312/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4465 - val_loss: 0.3385\n",
      "Epoch 313/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4443 - val_loss: 0.3370\n",
      "Epoch 314/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4421 - val_loss: 0.3354\n",
      "Epoch 315/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4399 - val_loss: 0.3339\n",
      "Epoch 316/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4377 - val_loss: 0.3323\n",
      "Epoch 317/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4355 - val_loss: 0.3308\n",
      "Epoch 318/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4332 - val_loss: 0.3291\n",
      "Epoch 319/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4310 - val_loss: 0.3274\n",
      "Epoch 320/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4287 - val_loss: 0.3257\n",
      "Epoch 321/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4264 - val_loss: 0.3239\n",
      "Epoch 322/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.3221\n",
      "Epoch 323/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4219 - val_loss: 0.3203\n",
      "Epoch 324/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4197 - val_loss: 0.3184\n",
      "Epoch 325/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4175 - val_loss: 0.3166\n",
      "Epoch 326/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4152 - val_loss: 0.3148\n",
      "Epoch 327/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4130 - val_loss: 0.3130\n",
      "Epoch 328/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4108 - val_loss: 0.3112\n",
      "Epoch 329/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.3095\n",
      "Epoch 330/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4065 - val_loss: 0.3077\n",
      "Epoch 331/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4043 - val_loss: 0.3060\n",
      "Epoch 332/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4021 - val_loss: 0.3042\n",
      "Epoch 333/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.4000 - val_loss: 0.3025\n",
      "Epoch 334/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.3008\n",
      "Epoch 335/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.2990\n",
      "Epoch 336/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3934 - val_loss: 0.2973\n",
      "Epoch 337/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.2955\n",
      "Epoch 338/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3891 - val_loss: 0.2938\n",
      "Epoch 339/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3869 - val_loss: 0.2921\n",
      "Epoch 340/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3848 - val_loss: 0.2904\n",
      "Epoch 341/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3826 - val_loss: 0.2887\n",
      "Epoch 342/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3804 - val_loss: 0.2870\n",
      "Epoch 343/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3783 - val_loss: 0.2852\n",
      "Epoch 344/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3761 - val_loss: 0.2835\n",
      "Epoch 345/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3740 - val_loss: 0.2818\n",
      "Epoch 346/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3719 - val_loss: 0.2801\n",
      "Epoch 347/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3699 - val_loss: 0.2785\n",
      "Epoch 348/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3679 - val_loss: 0.2769\n",
      "Epoch 349/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3658 - val_loss: 0.2753\n",
      "Epoch 350/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3638 - val_loss: 0.2737\n",
      "Epoch 351/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3618 - val_loss: 0.2720\n",
      "Epoch 352/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3597 - val_loss: 0.2704\n",
      "Epoch 353/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3577 - val_loss: 0.2688\n",
      "Epoch 354/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3557 - val_loss: 0.2672\n",
      "Epoch 355/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3537 - val_loss: 0.2656\n",
      "Epoch 356/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3517 - val_loss: 0.2640\n",
      "Epoch 357/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3497 - val_loss: 0.2625\n",
      "Epoch 358/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3478 - val_loss: 0.2609\n",
      "Epoch 359/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3458 - val_loss: 0.2594\n",
      "Epoch 360/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3439 - val_loss: 0.2579\n",
      "Epoch 361/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3420 - val_loss: 0.2564\n",
      "Epoch 362/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3401 - val_loss: 0.2549\n",
      "Epoch 363/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3382 - val_loss: 0.2534\n",
      "Epoch 364/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3363 - val_loss: 0.2519\n",
      "Epoch 365/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3344 - val_loss: 0.2504\n",
      "Epoch 366/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3325 - val_loss: 0.2490\n",
      "Epoch 367/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.2475\n",
      "Epoch 368/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3288 - val_loss: 0.2461\n",
      "Epoch 369/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.2446\n",
      "Epoch 370/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3252 - val_loss: 0.2432\n",
      "Epoch 371/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3234 - val_loss: 0.2418\n",
      "Epoch 372/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3217 - val_loss: 0.2404\n",
      "Epoch 373/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3199 - val_loss: 0.2390\n",
      "Epoch 374/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3181 - val_loss: 0.2376\n",
      "Epoch 375/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 0.2362\n",
      "Epoch 376/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3147 - val_loss: 0.2348\n",
      "Epoch 377/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.3129 - val_loss: 0.2334\n",
      "Epoch 378/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.3112 - val_loss: 0.2321\n",
      "Epoch 379/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3094 - val_loss: 0.2307\n",
      "Epoch 380/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3077 - val_loss: 0.2293\n",
      "Epoch 381/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3060 - val_loss: 0.2279\n",
      "Epoch 382/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3043 - val_loss: 0.2266\n",
      "Epoch 383/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.3026 - val_loss: 0.2253\n",
      "Epoch 384/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3010 - val_loss: 0.2240\n",
      "Epoch 385/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2993 - val_loss: 0.2227\n",
      "Epoch 386/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2977 - val_loss: 0.2214\n",
      "Epoch 387/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2961 - val_loss: 0.2202\n",
      "Epoch 388/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2945 - val_loss: 0.2189\n",
      "Epoch 389/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2929 - val_loss: 0.2177\n",
      "Epoch 390/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2913 - val_loss: 0.2164\n",
      "Epoch 391/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2898 - val_loss: 0.2152\n",
      "Epoch 392/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2882 - val_loss: 0.2140\n",
      "Epoch 393/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2867 - val_loss: 0.2128\n",
      "Epoch 394/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2852 - val_loss: 0.2117\n",
      "Epoch 395/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2837 - val_loss: 0.2105\n",
      "Epoch 396/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2822 - val_loss: 0.2094\n",
      "Epoch 397/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2807 - val_loss: 0.2082\n",
      "Epoch 398/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2792 - val_loss: 0.2071\n",
      "Epoch 399/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2777 - val_loss: 0.2059\n",
      "Epoch 400/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.2762 - val_loss: 0.2047\n",
      "Epoch 401/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2747 - val_loss: 0.2036\n",
      "Epoch 402/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2733 - val_loss: 0.2025\n",
      "Epoch 403/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2719 - val_loss: 0.2014\n",
      "Epoch 404/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.2704 - val_loss: 0.2003\n",
      "Epoch 405/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2691 - val_loss: 0.1993\n",
      "Epoch 406/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2677 - val_loss: 0.1982\n",
      "Epoch 407/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2663 - val_loss: 0.1972\n",
      "Epoch 408/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2650 - val_loss: 0.1961\n",
      "Epoch 409/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2636 - val_loss: 0.1951\n",
      "Epoch 410/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2623 - val_loss: 0.1941\n",
      "Epoch 411/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2610 - val_loss: 0.1931\n",
      "Epoch 412/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2597 - val_loss: 0.1921\n",
      "Epoch 413/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2584 - val_loss: 0.1911\n",
      "Epoch 414/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2571 - val_loss: 0.1901\n",
      "Epoch 415/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2558 - val_loss: 0.1892\n",
      "Epoch 416/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2545 - val_loss: 0.1882\n",
      "Epoch 417/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2533 - val_loss: 0.1872\n",
      "Epoch 418/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2520 - val_loss: 0.1863\n",
      "Epoch 419/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2507 - val_loss: 0.1853\n",
      "Epoch 420/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2495 - val_loss: 0.1844\n",
      "Epoch 421/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2483 - val_loss: 0.1835\n",
      "Epoch 422/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2471 - val_loss: 0.1826\n",
      "Epoch 423/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2458 - val_loss: 0.1817\n",
      "Epoch 424/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2446 - val_loss: 0.1809\n",
      "Epoch 425/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2435 - val_loss: 0.1800\n",
      "Epoch 426/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.1791\n",
      "Epoch 427/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2411 - val_loss: 0.1783\n",
      "Epoch 428/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2400 - val_loss: 0.1774\n",
      "Epoch 429/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2389 - val_loss: 0.1766\n",
      "Epoch 430/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2378 - val_loss: 0.1758\n",
      "Epoch 431/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2367 - val_loss: 0.1749\n",
      "Epoch 432/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2356 - val_loss: 0.1741\n",
      "Epoch 433/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2345 - val_loss: 0.1733\n",
      "Epoch 434/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2334 - val_loss: 0.1726\n",
      "Epoch 435/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2324 - val_loss: 0.1718\n",
      "Epoch 436/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2314 - val_loss: 0.1711\n",
      "Epoch 437/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2303 - val_loss: 0.1703\n",
      "Epoch 438/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2293 - val_loss: 0.1696\n",
      "Epoch 439/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.2283 - val_loss: 0.1688\n",
      "Epoch 440/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2273 - val_loss: 0.1681\n",
      "Epoch 441/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2262 - val_loss: 0.1674\n",
      "Epoch 442/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2253 - val_loss: 0.1666\n",
      "Epoch 443/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2243 - val_loss: 0.1660\n",
      "Epoch 444/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.2234 - val_loss: 0.1653\n",
      "Epoch 445/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.1646\n",
      "Epoch 446/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2214 - val_loss: 0.1639\n",
      "Epoch 447/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2205 - val_loss: 0.1632\n",
      "Epoch 448/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2195 - val_loss: 0.1625\n",
      "Epoch 449/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2186 - val_loss: 0.1618\n",
      "Epoch 450/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2176 - val_loss: 0.1611\n",
      "Epoch 451/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2167 - val_loss: 0.1605\n",
      "Epoch 452/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2158 - val_loss: 0.1598\n",
      "Epoch 453/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2148 - val_loss: 0.1591\n",
      "Epoch 454/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.2139 - val_loss: 0.1584\n",
      "Epoch 455/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2130 - val_loss: 0.1578\n",
      "Epoch 456/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.2121 - val_loss: 0.1571\n",
      "Epoch 457/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2112 - val_loss: 0.1565\n",
      "Epoch 458/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2103 - val_loss: 0.1559\n",
      "Epoch 459/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2094 - val_loss: 0.1553\n",
      "Epoch 460/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2086 - val_loss: 0.1546\n",
      "Epoch 461/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2077 - val_loss: 0.1540\n",
      "Epoch 462/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2069 - val_loss: 0.1534\n",
      "Epoch 463/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2060 - val_loss: 0.1528\n",
      "Epoch 464/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2052 - val_loss: 0.1522\n",
      "Epoch 465/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2044 - val_loss: 0.1517\n",
      "Epoch 466/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2036 - val_loss: 0.1511\n",
      "Epoch 467/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2027 - val_loss: 0.1505\n",
      "Epoch 468/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2019 - val_loss: 0.1500\n",
      "Epoch 469/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.1494\n",
      "Epoch 470/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.2004 - val_loss: 0.1489\n",
      "Epoch 471/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1996 - val_loss: 0.1483\n",
      "Epoch 472/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1989 - val_loss: 0.1478\n",
      "Epoch 473/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1981 - val_loss: 0.1473\n",
      "Epoch 474/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1974 - val_loss: 0.1468\n",
      "Epoch 475/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1966 - val_loss: 0.1462\n",
      "Epoch 476/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1959 - val_loss: 0.1457\n",
      "Epoch 477/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 0.1453\n",
      "Epoch 478/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1945 - val_loss: 0.1448\n",
      "Epoch 479/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1938 - val_loss: 0.1442\n",
      "Epoch 480/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1931 - val_loss: 0.1438\n",
      "Epoch 481/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1924 - val_loss: 0.1433\n",
      "Epoch 482/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1917 - val_loss: 0.1428\n",
      "Epoch 483/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.1423\n",
      "Epoch 484/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1903 - val_loss: 0.1418\n",
      "Epoch 485/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1896 - val_loss: 0.1414\n",
      "Epoch 486/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1889 - val_loss: 0.1409\n",
      "Epoch 487/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.1405\n",
      "Epoch 488/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.1400\n",
      "Epoch 489/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1870 - val_loss: 0.1396\n",
      "Epoch 490/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1392\n",
      "Epoch 491/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1387\n",
      "Epoch 492/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1383\n",
      "Epoch 493/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.1379\n",
      "Epoch 494/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.1375\n",
      "Epoch 495/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.1371\n",
      "Epoch 496/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1826 - val_loss: 0.1367\n",
      "Epoch 497/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1820 - val_loss: 0.1363\n",
      "Epoch 498/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.1359\n",
      "Epoch 499/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.1355\n",
      "Epoch 500/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1803 - val_loss: 0.1351\n",
      "Epoch 501/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1797 - val_loss: 0.1347\n",
      "Epoch 502/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.1343\n",
      "Epoch 503/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.1340\n",
      "Epoch 504/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 0.1336\n",
      "Epoch 505/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1774 - val_loss: 0.1332\n",
      "Epoch 506/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1769 - val_loss: 0.1329\n",
      "Epoch 507/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1764 - val_loss: 0.1325\n",
      "Epoch 508/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1758 - val_loss: 0.1322\n",
      "Epoch 509/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1753 - val_loss: 0.1318\n",
      "Epoch 510/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1748 - val_loss: 0.1315\n",
      "Epoch 511/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1742 - val_loss: 0.1312\n",
      "Epoch 512/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 0.1308\n",
      "Epoch 513/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1732 - val_loss: 0.1305\n",
      "Epoch 514/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1727 - val_loss: 0.1302\n",
      "Epoch 515/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1722 - val_loss: 0.1298\n",
      "Epoch 516/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1295\n",
      "Epoch 517/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1292\n",
      "Epoch 518/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1707 - val_loss: 0.1289\n",
      "Epoch 519/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1702 - val_loss: 0.1286\n",
      "Epoch 520/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1697 - val_loss: 0.1282\n",
      "Epoch 521/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1692 - val_loss: 0.1279\n",
      "Epoch 522/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1688 - val_loss: 0.1277\n",
      "Epoch 523/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1683 - val_loss: 0.1274\n",
      "Epoch 524/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1678 - val_loss: 0.1271\n",
      "Epoch 525/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1674 - val_loss: 0.1268\n",
      "Epoch 526/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1669 - val_loss: 0.1265\n",
      "Epoch 527/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1664 - val_loss: 0.1262\n",
      "Epoch 528/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1660 - val_loss: 0.1259\n",
      "Epoch 529/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1656 - val_loss: 0.1256\n",
      "Epoch 530/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1651 - val_loss: 0.1254\n",
      "Epoch 531/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1647 - val_loss: 0.1251\n",
      "Epoch 532/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1642 - val_loss: 0.1248\n",
      "Epoch 533/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1638 - val_loss: 0.1246\n",
      "Epoch 534/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1634 - val_loss: 0.1243\n",
      "Epoch 535/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1629 - val_loss: 0.1240\n",
      "Epoch 536/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1625 - val_loss: 0.1237\n",
      "Epoch 537/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1621 - val_loss: 0.1235\n",
      "Epoch 538/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1617 - val_loss: 0.1232\n",
      "Epoch 539/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1612 - val_loss: 0.1230\n",
      "Epoch 540/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1608 - val_loss: 0.1227\n",
      "Epoch 541/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1604 - val_loss: 0.1225\n",
      "Epoch 542/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1600 - val_loss: 0.1222\n",
      "Epoch 543/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1596 - val_loss: 0.1220\n",
      "Epoch 544/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1592 - val_loss: 0.1217\n",
      "Epoch 545/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1588 - val_loss: 0.1215\n",
      "Epoch 546/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1584 - val_loss: 0.1212\n",
      "Epoch 547/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1580 - val_loss: 0.1210\n",
      "Epoch 548/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1576 - val_loss: 0.1207\n",
      "Epoch 549/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1572 - val_loss: 0.1205\n",
      "Epoch 550/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1569 - val_loss: 0.1203\n",
      "Epoch 551/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1565 - val_loss: 0.1200\n",
      "Epoch 552/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1561 - val_loss: 0.1198\n",
      "Epoch 553/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1196\n",
      "Epoch 554/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1194\n",
      "Epoch 555/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1191\n",
      "Epoch 556/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1189\n",
      "Epoch 557/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1187\n",
      "Epoch 558/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1185\n",
      "Epoch 559/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1183\n",
      "Epoch 560/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1181\n",
      "Epoch 561/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1528 - val_loss: 0.1178\n",
      "Epoch 562/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1525 - val_loss: 0.1176\n",
      "Epoch 563/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1521 - val_loss: 0.1174\n",
      "Epoch 564/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1518 - val_loss: 0.1172\n",
      "Epoch 565/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1514 - val_loss: 0.1170\n",
      "Epoch 566/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1511 - val_loss: 0.1168\n",
      "Epoch 567/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1507 - val_loss: 0.1166\n",
      "Epoch 568/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.1164\n",
      "Epoch 569/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1501 - val_loss: 0.1163\n",
      "Epoch 570/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.1161\n",
      "Epoch 571/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 0.1159\n",
      "Epoch 572/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1491 - val_loss: 0.1157\n",
      "Epoch 573/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.1155\n",
      "Epoch 574/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1153\n",
      "Epoch 575/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1481 - val_loss: 0.1151\n",
      "Epoch 576/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.1149\n",
      "Epoch 577/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1474 - val_loss: 0.1147\n",
      "Epoch 578/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1471 - val_loss: 0.1146\n",
      "Epoch 579/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1468 - val_loss: 0.1144\n",
      "Epoch 580/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1465 - val_loss: 0.1142\n",
      "Epoch 581/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1462 - val_loss: 0.1140\n",
      "Epoch 582/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1458 - val_loss: 0.1138\n",
      "Epoch 583/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1455 - val_loss: 0.1137\n",
      "Epoch 584/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 0.1135\n",
      "Epoch 585/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.1133\n",
      "Epoch 586/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1131\n",
      "Epoch 587/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1443 - val_loss: 0.1129\n",
      "Epoch 588/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1440 - val_loss: 0.1128\n",
      "Epoch 589/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1437 - val_loss: 0.1126\n",
      "Epoch 590/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1434 - val_loss: 0.1124\n",
      "Epoch 591/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1430 - val_loss: 0.1122\n",
      "Epoch 592/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1427 - val_loss: 0.1121\n",
      "Epoch 593/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1424 - val_loss: 0.1119\n",
      "Epoch 594/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1421 - val_loss: 0.1117\n",
      "Epoch 595/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1419 - val_loss: 0.1115\n",
      "Epoch 596/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1416 - val_loss: 0.1114\n",
      "Epoch 597/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1413 - val_loss: 0.1112\n",
      "Epoch 598/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.1410 - val_loss: 0.1110\n",
      "Epoch 599/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.1407 - val_loss: 0.1109\n",
      "Epoch 600/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1404 - val_loss: 0.1107\n",
      "Epoch 601/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1401 - val_loss: 0.1105\n",
      "Epoch 602/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1398 - val_loss: 0.1104\n",
      "Epoch 603/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1396 - val_loss: 0.1102\n",
      "Epoch 604/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1393 - val_loss: 0.1100\n",
      "Epoch 605/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1390 - val_loss: 0.1099\n",
      "Epoch 606/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1387 - val_loss: 0.1097\n",
      "Epoch 607/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1384 - val_loss: 0.1095\n",
      "Epoch 608/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1381 - val_loss: 0.1093\n",
      "Epoch 609/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1379 - val_loss: 0.1092\n",
      "Epoch 610/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1376 - val_loss: 0.1090\n",
      "Epoch 611/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1373 - val_loss: 0.1088\n",
      "Epoch 612/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1370 - val_loss: 0.1087\n",
      "Epoch 613/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1367 - val_loss: 0.1085\n",
      "Epoch 614/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1365 - val_loss: 0.1083\n",
      "Epoch 615/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1362 - val_loss: 0.1081\n",
      "Epoch 616/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1359 - val_loss: 0.1080\n",
      "Epoch 617/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1357 - val_loss: 0.1078\n",
      "Epoch 618/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1076\n",
      "Epoch 619/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1351 - val_loss: 0.1075\n",
      "Epoch 620/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1349 - val_loss: 0.1073\n",
      "Epoch 621/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 0.1071\n",
      "Epoch 622/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1343 - val_loss: 0.1069\n",
      "Epoch 623/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 0.1068\n",
      "Epoch 624/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1066\n",
      "Epoch 625/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 0.1064\n",
      "Epoch 626/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.1063\n",
      "Epoch 627/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.1061\n",
      "Epoch 628/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1327 - val_loss: 0.1059\n",
      "Epoch 629/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1325 - val_loss: 0.1057\n",
      "Epoch 630/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.1056\n",
      "Epoch 631/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1054\n",
      "Epoch 632/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1317 - val_loss: 0.1052\n",
      "Epoch 633/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1315 - val_loss: 0.1051\n",
      "Epoch 634/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1312 - val_loss: 0.1049\n",
      "Epoch 635/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1310 - val_loss: 0.1047\n",
      "Epoch 636/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1307 - val_loss: 0.1045\n",
      "Epoch 637/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1044\n",
      "Epoch 638/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1302 - val_loss: 0.1042\n",
      "Epoch 639/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1300 - val_loss: 0.1040\n",
      "Epoch 640/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1039\n",
      "Epoch 641/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 0.1037\n",
      "Epoch 642/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1292 - val_loss: 0.1035\n",
      "Epoch 643/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1290 - val_loss: 0.1034\n",
      "Epoch 644/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1032\n",
      "Epoch 645/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.1030\n",
      "Epoch 646/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.1029\n",
      "Epoch 647/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.1027\n",
      "Epoch 648/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1025\n",
      "Epoch 649/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 0.1023\n",
      "Epoch 650/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 0.1022\n",
      "Epoch 651/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1270 - val_loss: 0.1020\n",
      "Epoch 652/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1268 - val_loss: 0.1019\n",
      "Epoch 653/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1017\n",
      "Epoch 654/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1263 - val_loss: 0.1015\n",
      "Epoch 655/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1260 - val_loss: 0.1014\n",
      "Epoch 656/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1258 - val_loss: 0.1012\n",
      "Epoch 657/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1256 - val_loss: 0.1010\n",
      "Epoch 658/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1253 - val_loss: 0.1009\n",
      "Epoch 659/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1251 - val_loss: 0.1007\n",
      "Epoch 660/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.1249 - val_loss: 0.1006\n",
      "Epoch 661/1000\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 0.1246 - val_loss: 0.1004\n",
      "Epoch 662/1000\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 0.1244 - val_loss: 0.1002\n",
      "Epoch 663/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.1242 - val_loss: 0.1001\n",
      "Epoch 664/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1239 - val_loss: 0.0999\n",
      "Epoch 665/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1237 - val_loss: 0.0997\n",
      "Epoch 666/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1234 - val_loss: 0.0996\n",
      "Epoch 667/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1232 - val_loss: 0.0994\n",
      "Epoch 668/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1230 - val_loss: 0.0993\n",
      "Epoch 669/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1227 - val_loss: 0.0991\n",
      "Epoch 670/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1225 - val_loss: 0.0989\n",
      "Epoch 671/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1223 - val_loss: 0.0988\n",
      "Epoch 672/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1220 - val_loss: 0.0986\n",
      "Epoch 673/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1218 - val_loss: 0.0984\n",
      "Epoch 674/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1216 - val_loss: 0.0983\n",
      "Epoch 675/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1214 - val_loss: 0.0981\n",
      "Epoch 676/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1211 - val_loss: 0.0980\n",
      "Epoch 677/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1209 - val_loss: 0.0978\n",
      "Epoch 678/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1207 - val_loss: 0.0976\n",
      "Epoch 679/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1204 - val_loss: 0.0975\n",
      "Epoch 680/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1202 - val_loss: 0.0973\n",
      "Epoch 681/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.0972\n",
      "Epoch 682/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1197 - val_loss: 0.0970\n",
      "Epoch 683/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.0968\n",
      "Epoch 684/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.0967\n",
      "Epoch 685/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.0965\n",
      "Epoch 686/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 0.0964\n",
      "Epoch 687/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.0962\n",
      "Epoch 688/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1184 - val_loss: 0.0960\n",
      "Epoch 689/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.0959\n",
      "Epoch 690/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.0957\n",
      "Epoch 691/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.0955\n",
      "Epoch 692/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1174 - val_loss: 0.0954\n",
      "Epoch 693/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.0952\n",
      "Epoch 694/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 0.0950\n",
      "Epoch 695/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1168 - val_loss: 0.0949\n",
      "Epoch 696/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.0947\n",
      "Epoch 697/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1163 - val_loss: 0.0946\n",
      "Epoch 698/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.0944\n",
      "Epoch 699/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.0942\n",
      "Epoch 700/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.0941\n",
      "Epoch 701/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1154 - val_loss: 0.0939\n",
      "Epoch 702/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.0937\n",
      "Epoch 703/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.0936\n",
      "Epoch 704/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.0934\n",
      "Epoch 705/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1145 - val_loss: 0.0933\n",
      "Epoch 706/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 0.0931\n",
      "Epoch 707/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1141 - val_loss: 0.0929\n",
      "Epoch 708/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.0928\n",
      "Epoch 709/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1137 - val_loss: 0.0926\n",
      "Epoch 710/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.0925\n",
      "Epoch 711/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1132 - val_loss: 0.0923\n",
      "Epoch 712/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.0922\n",
      "Epoch 713/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.0920\n",
      "Epoch 714/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.0918\n",
      "Epoch 715/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.0917\n",
      "Epoch 716/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1121 - val_loss: 0.0915\n",
      "Epoch 717/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1119 - val_loss: 0.0913\n",
      "Epoch 718/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1117 - val_loss: 0.0912\n",
      "Epoch 719/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1115 - val_loss: 0.0910\n",
      "Epoch 720/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1113 - val_loss: 0.0908\n",
      "Epoch 721/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1111 - val_loss: 0.0907\n",
      "Epoch 722/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1108 - val_loss: 0.0905\n",
      "Epoch 723/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1106 - val_loss: 0.0903\n",
      "Epoch 724/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1104 - val_loss: 0.0902\n",
      "Epoch 725/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1102 - val_loss: 0.0900\n",
      "Epoch 726/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1100 - val_loss: 0.0898\n",
      "Epoch 727/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1098 - val_loss: 0.0897\n",
      "Epoch 728/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1096 - val_loss: 0.0895\n",
      "Epoch 729/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1093 - val_loss: 0.0894\n",
      "Epoch 730/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.0892\n",
      "Epoch 731/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.0890\n",
      "Epoch 732/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1087 - val_loss: 0.0889\n",
      "Epoch 733/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1085 - val_loss: 0.0887\n",
      "Epoch 734/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.0885\n",
      "Epoch 735/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1081 - val_loss: 0.0884\n",
      "Epoch 736/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1078 - val_loss: 0.0882\n",
      "Epoch 737/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1076 - val_loss: 0.0880\n",
      "Epoch 738/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1074 - val_loss: 0.0879\n",
      "Epoch 739/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.0877\n",
      "Epoch 740/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1070 - val_loss: 0.0876\n",
      "Epoch 741/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.1068 - val_loss: 0.0874\n",
      "Epoch 742/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1066 - val_loss: 0.0872\n",
      "Epoch 743/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1063 - val_loss: 0.0871\n",
      "Epoch 744/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1061 - val_loss: 0.0869\n",
      "Epoch 745/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.0867\n",
      "Epoch 746/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.0866\n",
      "Epoch 747/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1055 - val_loss: 0.0864\n",
      "Epoch 748/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.0863\n",
      "Epoch 749/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.0861\n",
      "Epoch 750/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 0.0859\n",
      "Epoch 751/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.0858\n",
      "Epoch 752/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1045 - val_loss: 0.0856\n",
      "Epoch 753/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1042 - val_loss: 0.0855\n",
      "Epoch 754/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 0.0853\n",
      "Epoch 755/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.0851\n",
      "Epoch 756/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1036 - val_loss: 0.0850\n",
      "Epoch 757/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1034 - val_loss: 0.0848\n",
      "Epoch 758/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1032 - val_loss: 0.0846\n",
      "Epoch 759/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.0845\n",
      "Epoch 760/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.0843\n",
      "Epoch 761/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1026 - val_loss: 0.0842\n",
      "Epoch 762/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1024 - val_loss: 0.0840\n",
      "Epoch 763/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.0838\n",
      "Epoch 764/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1020 - val_loss: 0.0837\n",
      "Epoch 765/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.0835\n",
      "Epoch 766/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1016 - val_loss: 0.0833\n",
      "Epoch 767/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.0831\n",
      "Epoch 768/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.1012 - val_loss: 0.0830\n",
      "Epoch 769/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1010 - val_loss: 0.0828\n",
      "Epoch 770/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1008 - val_loss: 0.0826\n",
      "Epoch 771/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1006 - val_loss: 0.0825\n",
      "Epoch 772/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1004 - val_loss: 0.0823\n",
      "Epoch 773/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.1002 - val_loss: 0.0822\n",
      "Epoch 774/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.0820\n",
      "Epoch 775/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.0818\n",
      "Epoch 776/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0817\n",
      "Epoch 777/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0994 - val_loss: 0.0815\n",
      "Epoch 778/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0992 - val_loss: 0.0813\n",
      "Epoch 779/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.0812\n",
      "Epoch 780/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0988 - val_loss: 0.0810\n",
      "Epoch 781/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0809\n",
      "Epoch 782/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.0807\n",
      "Epoch 783/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.0805\n",
      "Epoch 784/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.0804\n",
      "Epoch 785/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0802\n",
      "Epoch 786/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.0801\n",
      "Epoch 787/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.0799\n",
      "Epoch 788/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0798\n",
      "Epoch 789/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.0970 - val_loss: 0.0796\n",
      "Epoch 790/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.0794\n",
      "Epoch 791/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.0793\n",
      "Epoch 792/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.0791\n",
      "Epoch 793/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.0790\n",
      "Epoch 794/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.0788\n",
      "Epoch 795/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.0787\n",
      "Epoch 796/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.0785\n",
      "Epoch 797/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.0784\n",
      "Epoch 798/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.0782\n",
      "Epoch 799/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.0780\n",
      "Epoch 800/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0948 - val_loss: 0.0779\n",
      "Epoch 801/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0946 - val_loss: 0.0777\n",
      "Epoch 802/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0944 - val_loss: 0.0776\n",
      "Epoch 803/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0942 - val_loss: 0.0774\n",
      "Epoch 804/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0940 - val_loss: 0.0773\n",
      "Epoch 805/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0938 - val_loss: 0.0771\n",
      "Epoch 806/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.0770\n",
      "Epoch 807/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0935 - val_loss: 0.0769\n",
      "Epoch 808/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.0767\n",
      "Epoch 809/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.0766\n",
      "Epoch 810/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.0764\n",
      "Epoch 811/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0927 - val_loss: 0.0763\n",
      "Epoch 812/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.0761\n",
      "Epoch 813/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0760\n",
      "Epoch 814/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.0758\n",
      "Epoch 815/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0919 - val_loss: 0.0757\n",
      "Epoch 816/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.0756\n",
      "Epoch 817/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.0754\n",
      "Epoch 818/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0753\n",
      "Epoch 819/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.0752\n",
      "Epoch 820/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.0750\n",
      "Epoch 821/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.0749\n",
      "Epoch 822/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0906 - val_loss: 0.0747\n",
      "Epoch 823/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0905 - val_loss: 0.0746\n",
      "Epoch 824/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0903 - val_loss: 0.0745\n",
      "Epoch 825/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0901 - val_loss: 0.0743\n",
      "Epoch 826/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0742\n",
      "Epoch 827/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.0740\n",
      "Epoch 828/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.0739\n",
      "Epoch 829/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.0738\n",
      "Epoch 830/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0736\n",
      "Epoch 831/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0735\n",
      "Epoch 832/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0734\n",
      "Epoch 833/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.0732\n",
      "Epoch 834/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.0731\n",
      "Epoch 835/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0730\n",
      "Epoch 836/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0881 - val_loss: 0.0728\n",
      "Epoch 837/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.0727\n",
      "Epoch 838/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0726\n",
      "Epoch 839/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0724\n",
      "Epoch 840/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0723\n",
      "Epoch 841/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0872 - val_loss: 0.0722\n",
      "Epoch 842/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 843/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0868 - val_loss: 0.0719\n",
      "Epoch 844/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0867 - val_loss: 0.0718\n",
      "Epoch 845/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0865 - val_loss: 0.0716\n",
      "Epoch 846/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0863 - val_loss: 0.0715\n",
      "Epoch 847/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0861 - val_loss: 0.0714\n",
      "Epoch 848/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0860 - val_loss: 0.0713\n",
      "Epoch 849/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0858 - val_loss: 0.0711\n",
      "Epoch 850/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0856 - val_loss: 0.0710\n",
      "Epoch 851/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0854 - val_loss: 0.0709\n",
      "Epoch 852/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0853 - val_loss: 0.0708\n",
      "Epoch 853/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0851 - val_loss: 0.0706\n",
      "Epoch 854/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0849 - val_loss: 0.0705\n",
      "Epoch 855/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0848 - val_loss: 0.0704\n",
      "Epoch 856/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0846 - val_loss: 0.0703\n",
      "Epoch 857/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0844 - val_loss: 0.0701\n",
      "Epoch 858/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0842 - val_loss: 0.0700\n",
      "Epoch 859/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0841 - val_loss: 0.0699\n",
      "Epoch 860/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0839 - val_loss: 0.0697\n",
      "Epoch 861/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0837 - val_loss: 0.0696\n",
      "Epoch 862/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0836 - val_loss: 0.0695\n",
      "Epoch 863/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.0694\n",
      "Epoch 864/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0832 - val_loss: 0.0692\n",
      "Epoch 865/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0831 - val_loss: 0.0691\n",
      "Epoch 866/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0829 - val_loss: 0.0690\n",
      "Epoch 867/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0827 - val_loss: 0.0689\n",
      "Epoch 868/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0826 - val_loss: 0.0688\n",
      "Epoch 869/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0686\n",
      "Epoch 870/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0685\n",
      "Epoch 871/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0684\n",
      "Epoch 872/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0683\n",
      "Epoch 873/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0682\n",
      "Epoch 874/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0680\n",
      "Epoch 875/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0679\n",
      "Epoch 876/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0678\n",
      "Epoch 877/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0677\n",
      "Epoch 878/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0676\n",
      "Epoch 879/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0674\n",
      "Epoch 880/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0673\n",
      "Epoch 881/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0672\n",
      "Epoch 882/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0802 - val_loss: 0.0671\n",
      "Epoch 883/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0669\n",
      "Epoch 884/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0668\n",
      "Epoch 885/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0667\n",
      "Epoch 886/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0666\n",
      "Epoch 887/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0794 - val_loss: 0.0665\n",
      "Epoch 888/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0663\n",
      "Epoch 889/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0662\n",
      "Epoch 890/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0661\n",
      "Epoch 891/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0660\n",
      "Epoch 892/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0658\n",
      "Epoch 893/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0657\n",
      "Epoch 894/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0656\n",
      "Epoch 895/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0655\n",
      "Epoch 896/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0654\n",
      "Epoch 897/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0652\n",
      "Epoch 898/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0651\n",
      "Epoch 899/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0650\n",
      "Epoch 900/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0649\n",
      "Epoch 901/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0648\n",
      "Epoch 902/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0647\n",
      "Epoch 903/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0645\n",
      "Epoch 904/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0767 - val_loss: 0.0644\n",
      "Epoch 905/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0765 - val_loss: 0.0643\n",
      "Epoch 906/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0764 - val_loss: 0.0642\n",
      "Epoch 907/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0762 - val_loss: 0.0641\n",
      "Epoch 908/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0761 - val_loss: 0.0640\n",
      "Epoch 909/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0759 - val_loss: 0.0638\n",
      "Epoch 910/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0758 - val_loss: 0.0637\n",
      "Epoch 911/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0756 - val_loss: 0.0636\n",
      "Epoch 912/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0754 - val_loss: 0.0635\n",
      "Epoch 913/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0753 - val_loss: 0.0634\n",
      "Epoch 914/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0751 - val_loss: 0.0633\n",
      "Epoch 915/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0750 - val_loss: 0.0632\n",
      "Epoch 916/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0748 - val_loss: 0.0630\n",
      "Epoch 917/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0747 - val_loss: 0.0629\n",
      "Epoch 918/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0745 - val_loss: 0.0628\n",
      "Epoch 919/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0744 - val_loss: 0.0627\n",
      "Epoch 920/1000\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 0.0742 - val_loss: 0.0626\n",
      "Epoch 921/1000\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 0.0741 - val_loss: 0.0625\n",
      "Epoch 922/1000\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.0739 - val_loss: 0.0624\n",
      "Epoch 923/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0738 - val_loss: 0.0623\n",
      "Epoch 924/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0736 - val_loss: 0.0622\n",
      "Epoch 925/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0735 - val_loss: 0.0621\n",
      "Epoch 926/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0733 - val_loss: 0.0620\n",
      "Epoch 927/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0732 - val_loss: 0.0619\n",
      "Epoch 928/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0730 - val_loss: 0.0618\n",
      "Epoch 929/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0729 - val_loss: 0.0617\n",
      "Epoch 930/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0727 - val_loss: 0.0616\n",
      "Epoch 931/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0614\n",
      "Epoch 932/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0613\n",
      "Epoch 933/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.0612\n",
      "Epoch 934/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0611\n",
      "Epoch 935/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0610\n",
      "Epoch 936/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0609\n",
      "Epoch 937/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0608\n",
      "Epoch 938/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0607\n",
      "Epoch 939/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0606\n",
      "Epoch 940/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0605\n",
      "Epoch 941/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0604\n",
      "Epoch 942/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0603\n",
      "Epoch 943/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0602\n",
      "Epoch 944/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0601\n",
      "Epoch 945/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0600\n",
      "Epoch 946/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0599\n",
      "Epoch 947/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0598\n",
      "Epoch 948/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0598\n",
      "Epoch 949/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0597\n",
      "Epoch 950/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0596\n",
      "Epoch 951/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0595\n",
      "Epoch 952/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0594\n",
      "Epoch 953/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0593\n",
      "Epoch 954/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0592\n",
      "Epoch 955/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0591\n",
      "Epoch 956/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0590\n",
      "Epoch 957/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0589\n",
      "Epoch 958/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0588\n",
      "Epoch 959/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0685 - val_loss: 0.0587\n",
      "Epoch 960/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0586\n",
      "Epoch 961/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0585\n",
      "Epoch 962/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0584\n",
      "Epoch 963/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0583\n",
      "Epoch 964/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0582\n",
      "Epoch 965/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0677 - val_loss: 0.0581\n",
      "Epoch 966/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0676 - val_loss: 0.0580\n",
      "Epoch 967/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0674 - val_loss: 0.0579\n",
      "Epoch 968/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0673 - val_loss: 0.0578\n",
      "Epoch 969/1000\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0577\n",
      "Epoch 970/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0670 - val_loss: 0.0576\n",
      "Epoch 971/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0669 - val_loss: 0.0575\n",
      "Epoch 972/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0668 - val_loss: 0.0574\n",
      "Epoch 973/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0666 - val_loss: 0.0573\n",
      "Epoch 974/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0665 - val_loss: 0.0572\n",
      "Epoch 975/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0663 - val_loss: 0.0571\n",
      "Epoch 976/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0662 - val_loss: 0.0570\n",
      "Epoch 977/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0661 - val_loss: 0.0569\n",
      "Epoch 978/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0659 - val_loss: 0.0568\n",
      "Epoch 979/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0658 - val_loss: 0.0567\n",
      "Epoch 980/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0657 - val_loss: 0.0566\n",
      "Epoch 981/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0655 - val_loss: 0.0565\n",
      "Epoch 982/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0654 - val_loss: 0.0564\n",
      "Epoch 983/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0653 - val_loss: 0.0563\n",
      "Epoch 984/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0651 - val_loss: 0.0562\n",
      "Epoch 985/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0650 - val_loss: 0.0561\n",
      "Epoch 986/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0649 - val_loss: 0.0560\n",
      "Epoch 987/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0648 - val_loss: 0.0559\n",
      "Epoch 988/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0646 - val_loss: 0.0558\n",
      "Epoch 989/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0645 - val_loss: 0.0557\n",
      "Epoch 990/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0644 - val_loss: 0.0556\n",
      "Epoch 991/1000\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.0642 - val_loss: 0.0555\n",
      "Epoch 992/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0641 - val_loss: 0.0554\n",
      "Epoch 993/1000\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.0640 - val_loss: 0.0553\n",
      "Epoch 994/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0552\n",
      "Epoch 995/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0551\n",
      "Epoch 996/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0550\n",
      "Epoch 997/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0550\n",
      "Epoch 998/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0549\n",
      "Epoch 999/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0548\n",
      "Epoch 1000/1000\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0547\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a94ad118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_on_trained = model.predict(X_test) #prediction after training with respect to X. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c2feb",
   "metadata": {},
   "source": [
    "# Compare predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b12fe604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot values before and after the trainig using matplot \n",
    "compare_predictions(preds_on_untrained, preds_on_trained, y_test)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9578755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = df['price'].mean()\n",
    "y_std = df['price'].std() #this will be the additional code for getting the mean and standard values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9c887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
